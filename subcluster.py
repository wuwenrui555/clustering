# %%
import uuid
import pickle
from pathlib import Path
from typing import Any, Dict, Union

import anndata as ad
import matplotlib.pyplot as plt
import pandas as pd
import PyComplexHeatmap as pch
import scanpy as sc
from pydantic import BaseModel, Field, model_validator
from sklearn.cluster import KMeans
from tqdm import tqdm

TQDM_FORMAT = "{desc}: {percentage:3.0f}%|{bar:30}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"

# 1. clustering_sequence: record the sequence of clustering
# uuid_1, uuid_2, uuid_3, ...

# 2. clustering_result:
# Necessary fields:
# (1) clustering_id (uuid)
# (2) unit_id: id of the unit included in the clustering
# (3) cluster_id: id of the cluster assigned to the unit
# Optional fields:
# (4) annotation: annotation for the cluster (used for explicit clusters)
# (5) tag: tag for the cluster (used for non-explicit clusters)


# 3. cluster_id_manager:
# (1) unit_id: id of the unit included in the clustering
# (2) clustering results: one column for each clustering result, column name is
# the clustering id, value is the cluster id. Arrange the columns in the order of
# clustering_sequence.
# (3) latest_cluster_id: the latest cluster id for each unit, generated by
# concatenating the all cluster ids in the order of clustering_sequence.

# 4. cluster_labels_manager:
# (1) unit_id: id of the unit included in the clustering
# (2) annotation: annotation for the cluster (used for explicit clusters)
# (3) tag: tag for the cluster (used for non-explicit clusters)

# 5. summary: cluster_id_manager and cluster_label_manager
# (1) unit_id: id of the unit included in the clustering
# (2) clustering results: the clustering results of the unit, arranged in the
# order of clustering_sequence.
# (3) latest_cluster_id: the latest cluster id for each unit, generated by
# concatenating the all cluster ids in the order of clustering_sequence.
# (4) annotation: annotation for the latest cluster id (used for explicit clusters)
# (5) tag: tag for the latest cluster id (used for non-explicit clusters)


# File structure:
# output_dir/
#   clustering_sequence.txt: the sequence of clustering ids
#   clustering results/:
#     clustering_id_1.csv: the clustering result of the first clustering (unit_id,
#     cluster_id, annotation, tab_1, tab_2, ...)
#     clustering_id_2.csv: the clustering result of the second clustering

# Workflow:
# 1. Load the raw data (unit_id as row index, feature as column index)
# 2. Initialize the clustering result manager, load the clustering results from
#    the output_dir and map the cluster information to the raw data.
# 3. Subset the raw data based on the cluster information and perform subclustering.
# 4. Export the subclustering results to the output_dir.
# 5. Repeat the same workflow for the subclustering results.


# ClusteringResult >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


class ClusteringResult(BaseModel):
    """
    A class to record the result of clustering and manage the annotation and tag.
    Attributes:
    -----------
    clustering_id: str
        The id of the clustering.
    method: str
        The method used for clustering.
    unit_ids: List[str]
        The ids of each unit included in the clustering.
    cluster_ids: List[str]
        The cluster ids assigned to each unit.
    cluster_df: pd.DataFrame
        DataFrame to record the clustering result:
        - clustering_id: the id of the clustering process.
        - unit_ids: the ids of the units.
        - cluster_ids: the cluster ids assigned to the units.
        - annotation: the annotation for each cluster. If not specified, the
        cluster is non-explicit.
        - tag: the tag for each cluster. It is recommended to specify the tag for
        clusters with non-explicit annotation (mixed annotations), which makes it
        easier to select the non-explicit clusters for next clustering.
    """

    clustering_id: str
    method: str
    unit_ids: list[str]
    cluster_ids: list[str]
    cluster_df: pd.DataFrame = Field(default_factory=pd.DataFrame)

    model_config = {"arbitrary_types_allowed": True}

    # Custom initialization using model_validator in Pydantic v2
    @model_validator(mode="after")
    def init(self):
        """
        Initialization after model validation.
        """
        self.cluster_df = pd.DataFrame(
            {
                "clustering_id": self.clustering_id,
                "method": self.method,
                "unit_ids": self.unit_ids,
                "cluster_ids": self.cluster_ids,
            }
        )
        return self

    @classmethod
    def from_csv(cls, csv_f: Union[str, Path]):
        """
        Load a clustering result from a csv file.
        """
        cluster_df = pd.read_csv(csv_f)
        unit_ids = cluster_df["unit_ids"].astype(str).tolist()
        cluster_ids = cluster_df["cluster_ids"].astype(str).tolist()
        clustering_id_values = cluster_df["clustering_id"].unique()
        method_values = cluster_df["method"].unique()

        if len(clustering_id_values) != 1:
            raise ValueError("Only one clustering id is allowed.")
        if len(method_values) != 1:
            raise ValueError("Only one method is allowed.")

        clustering_id = clustering_id_values[0]
        method = method_values[0]

        # Create a new instance with the data from CSV
        return cls(
            unit_ids=unit_ids,
            method=method,
            cluster_ids=cluster_ids,
            clustering_id=clustering_id,
        )

    @classmethod
    def pop(cls, clustering_id: str, output_dir: Union[str, Path]):
        """
        Pop the clustering result from the stash.

        Parameters:
        -----------
        clustering_id: str
            The id of the clustering result to pop.
        output_dir: Union[str, Path]
            The directory to reload the clustering result. The stashed clustering
            result was saved under the `clustering_stash` subdirectory.

        Returns:
        --------
        ClusteringResult
            The loaded clustering result instance.
        """
        output_dir = Path(output_dir)
        input_file = output_dir / "clustering_stash" / f"{clustering_id}.pickle"

        if not input_file.exists():
            raise FileNotFoundError(
                f"No clustering result found for id: {clustering_id}"
            )

        with open(input_file, "rb") as f:
            return pickle.load(f)

    def add_annotation(self, annotation: dict[str, str]):
        """
        Add annotation to explicit clusters.

        Parameters:
        -----------
        annotation: dict[str, str]
            The annotation for each cluster with key as the cluster id and value as the annotation.
        """
        # Overwrite the existing annotation column
        if "annotation" in self.cluster_df.columns:
            self.cluster_df = self.cluster_df.drop(columns=["annotation"])
            print("Overwrite the existing annotation column.")

        # Create a mapping from cluster_id to annotation
        cluster_to_annotation = {}
        for cluster_id in self.cluster_df["cluster_ids"].unique():
            cluster_to_annotation[cluster_id] = annotation.get(cluster_id, "")

        # Add the annotation column
        self.cluster_df["annotation"] = self.cluster_df["cluster_ids"].map(
            cluster_to_annotation
        )

    def add_tag(self, tag: dict[str, str], tag_name: str = "tag"):
        """
        Add tag to the non-explicit clusters.

        Parameters:
        -----------
        tag: dict[str, str]
            The tag for each cluster with key as the cluster id and value as the tag.
        tag_name: str
            The name of the tag column.
        """
        # Overwrite the existing tag column
        if tag_name in self.cluster_df.columns:
            self.cluster_df = self.cluster_df.drop(columns=[tag_name])
            print(f"Overwrite the existing {tag_name} column.")

        # Create a mapping from cluster_id to tag
        cluster_to_tag = {}
        for cluster_id in self.cluster_df["cluster_ids"].unique():
            cluster_to_tag[cluster_id] = tag.get(cluster_id, "")

        # Add the tag column
        self.cluster_df[tag_name] = self.cluster_df["cluster_ids"].map(cluster_to_tag)

    def stash(self, output_dir: Union[str, Path]):
        """
        Temporarily save the clustering result to a csv file.

        Parameters:
        -----------
        output_dir: Union[str, Path]
            The directory to store the clustering result. The clustering result
            will be saved as `{self.clustering_id}.pickle` under the `clustering_stash`
            subdirectory.
        """
        output_dir = Path(output_dir)
        output_file = output_dir / "clustering_stash" / f"{self.clustering_id}.pickle"
        output_file.parent.mkdir(parents=True, exist_ok=True)
        with open(output_file, "wb") as f:
            pickle.dump(self, f)
        print(
            f"To reload the stashed clustering result:"
            f"\nClusteringResult.pop("
            f"\n    clustering_id='{self.clustering_id}',"
            f"\n    output_dir='{output_dir}'"
            f"\n)"
        )

    def save(self, output_dir: Union[str, Path]):
        """
        Save the clustering result to a csv file.

        Parameters:
        -----------
        output_dir: Union[str, Path]
            The directory to store the clustering result. The clustering result
            will be saved as `{self.clustering_id}.csv` under the `clustering_results`
            subdirectory.
        """
        output_dir = Path(output_dir)
        output_file = output_dir / "clustering_results" / f"{self.clustering_id}.csv"
        output_file.parent.mkdir(parents=True, exist_ok=True)
        self.cluster_df.to_csv(output_file, index=False)

        sequence_file = output_dir / "clustering_sequence.txt"
        if not sequence_file.exists():
            with open(sequence_file, "w") as f:
                f.write(f"{self.clustering_id}\n")
        else:
            with open(sequence_file, "a") as f:
                f.write(f"{self.clustering_id}\n")


# ClusteringResult <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


# Clustering functions >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


def run_clustering(
    adata: ad.AnnData,
    unit_ids: list[str],
    features: list[str],
    method: str = "phenograph",
    method_params: Dict[str, Any] | None = None,
    output_dir: Union[str, Path] = None,
) -> ClusteringResult:
    """
    Run clustering on the given data.
    """
    match method:
        case "phenograph":
            clustering_result = _run_clustering_phenograph(
                adata, unit_ids, features, method_params
            )
        case "kmeans":
            clustering_result = _run_clustering_kmeans(
                adata, unit_ids, features, method_params
            )
        case "leiden":
            clustering_result = _run_clustering_leiden(
                adata, unit_ids, features, method_params
            )
        case _:
            raise ValueError(f"Method {method} not supported.")

    if output_dir is not None:
        clustering_result.stash(output_dir)

    return clustering_result


def _run_clustering_phenograph(
    adata: ad.AnnData,
    unit_ids: list[str],
    features: list[str],
    method_params: Dict[str, Any] | None = None,
):
    """
    Run clustering using PhenoGraph.

    Parameters:
    -----------
    adata: AnnData
        The AnnData object to cluster.
    unit_ids: list[str]
        The unit IDs to cluster.
    features: list[str]
        The features to cluster.
    method_params: dict
        The parameters for the clustering method.

    Returns:
    --------
    ClusteringResult
    """
    if method_params is None:
        method_params = {}

    clustering_id = str(uuid.uuid4())
    adata_cluster = adata[unit_ids, features].copy()
    adata_cluster.obs.drop(columns=adata_cluster.obs.columns, inplace=True)

    sc.pp.pca(adata_cluster)
    sc.external.tl.phenograph(adata_cluster, **method_params)

    cluster_key = adata_cluster.obs.columns[0]
    cluster_ids = [str(cid) for cid in adata_cluster.obs[cluster_key]]
    unit_ids = [str(uid) for uid in adata_cluster.obs.index]

    return ClusteringResult(
        clustering_id=clustering_id,
        method="phenograph",
        unit_ids=unit_ids,
        cluster_ids=cluster_ids,
    )


def _run_clustering_kmeans(
    adata: ad.AnnData,
    unit_ids: list[str],
    features: list[str],
    method_params: Dict[str, Any] | None = None,
):
    """
    Run clustering using K-means.

    Parameters:
    -----------
    adata: AnnData
        The AnnData object to cluster.
    unit_ids: list[str]
        The unit IDs to cluster.
    features: list[str]
        The features to cluster.
    method_params: dict
        The parameters for the clustering method.

    Returns:
    --------
    ClusteringResult
    """
    if method_params is None:
        method_params = {}

    clustering_id = str(uuid.uuid4())
    adata_cluster = adata[unit_ids, features].copy()
    adata_cluster.obs.drop(columns=adata_cluster.obs.columns, inplace=True)

    kmeans = KMeans(**method_params)
    kmeans.fit(adata_cluster.X)

    # Get cluster assignments
    cluster_ids = [str(cid) for cid in kmeans.labels_]
    unit_ids = [str(uid) for uid in adata_cluster.obs.index]

    return ClusteringResult(
        clustering_id=clustering_id,
        method="kmeans",
        unit_ids=unit_ids,
        cluster_ids=cluster_ids,
    )


# TODO: implement leiden clustering
def _run_clustering_leiden(
    adata: ad.AnnData,
    unit_ids: list[str],
    features: list[str],
    method_params: Dict[str, Any] | None = None,
):
    print("Leiden clustering is not implemented yet.")
    return None


# Clustering functions <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

# Plotting functions >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

PRESET_HEATMAP_KWARGS = {
    "row_cluster": False,
    "col_cluster": True,
    "show_rownames": True,
    "show_colnames": True,
    "row_names_side": "right",
    "col_names_side": "bottom",
    "col_dendrogram": True,
    "col_dendrogram_size": 15,
    "tree_kws": {"colors": "blue"},
    "cmap": "RdBu_r",
    "legend_gap": 5,
    "xticklabels_kws": {"labelrotation": -90, "labelcolor": "blue"},
    "plot": False,
    "verbose": 0,
}


def _plot_clustering_heatmap(
    adata: ad.AnnData,
    clustering_result: ClusteringResult,
    features: list[str],
    plot_value: str = "zscore",
    x_label: str = "cluster",
    preset_heatmap_kwargs: str = "PRESET_HEATMAP_KWARGS",
    **kwargs: dict[str, Any],
) -> pch.ClusterMapPlotter:
    """
    Plot a heatmap of cluster data

    This function creates a heatmap visualization using either z-scores or mean
    values of features across clusters. The heatmap includes annotations showing
    cell count and mean cell size for each cluster.

    Parameters
    ----------
    adata : ad.AnnData
        AnnData object containing the cluster data.
    clustering_result : ClusteringResult
        Object containing clustering assignments and metadata.
    features : list[str]
        List of features (genes/markers) to display in the heatmap.
    plot_value : str, optional
        Type of values to plot:
        - "zscore": Z-score normalized values (default)
        - "mean": Raw mean values
    x_label : str, optional
        Label for the x-axis, by default "cluster". Can be "cluster", "annotation",
        or "tag". If "cluster", the cluster IDs will be used as the x-axis labels.
        If "annotation" or "tag", the annotation or tag will be used as the x-axis
        labels if they are not empty. Otherwise, the cluster IDs will be used as
        the x-axis labels.
    preset_heatmap_kwargs : str, optional
        Name of preset kwargs dict for PyComplexHeatmap.ClusterMapPlotter.
        Default is "PRESET_HEATMAP_KWARGS".
    **kwargs : dict[str, Any]
        Additional kwargs passed to PyComplexHeatmap.ClusterMapPlotter.
        Common options include:
        - vmin, vmax: Value range limits
        - center: Center value for diverging colormaps
        - cmap: Colormap name
        - annot: Show data values in cells
        See PyComplexHeatmap docs for full list of options.

    Returns
    -------
    pch.ClusterMapPlotter
        Configured heatmap plotter object ready for rendering.
    """
    if preset_heatmap_kwargs == "PRESET_HEATMAP_KWARGS":
        preset_heatmap_kwargs = PRESET_HEATMAP_KWARGS.copy()
    if plot_value == "mean":
        if kwargs.get("cmap") is None and preset_heatmap_kwargs.get("cmap") == "RdBu_r":
            kwargs["cmap"] = "Reds"
    preset_heatmap_kwargs.update(kwargs)

    unit_ids = clustering_result.unit_ids
    cluster_ids = clustering_result.cluster_ids
    try:
        cluster_ids_order = sorted([int(i) for i in set(cluster_ids)])
    except ValueError:
        cluster_ids_order = sorted(set(cluster_ids))
    cluster_ids_order = [str(i) for i in cluster_ids_order]

    adata_clustering = adata[unit_ids, features]
    metadata = adata_clustering.obs
    clustering_data = adata_clustering.to_df()

    if plot_value == "zscore":
        cluster_mean = clustering_data.groupby(cluster_ids).mean()
        population_mean = clustering_data.mean(axis=0)
        population_std = clustering_data.std(axis=0)
        cluster_zscore = (cluster_mean - population_mean) / population_std
        heatmap_df = cluster_zscore.T
        preset_heatmap_kwargs["label"] = "zscore"
    elif plot_value == "mean":
        cluster_mean = clustering_data.groupby(cluster_ids).mean()
        heatmap_df = cluster_mean.T
        preset_heatmap_kwargs["label"] = "mean"
    else:
        raise ValueError(f"Invalid plot_value: {plot_value}")
    heatmap_df = heatmap_df[cluster_ids_order]

    cluster_count = pd.Series(cluster_ids).value_counts().to_frame(name="count")
    cluster_mean_cellsize = metadata.groupby(cluster_ids)["cellSize"].mean().to_frame()

    if x_label == "cluster":
        columns = ["cluster_ids"]
    elif x_label == "annotation":
        columns = ["annotation", "cluster_ids"]
    else:
        columns = [x_label, "annotation", "cluster_ids"]
    columns = [col for col in columns if col in clustering_result.cluster_df.columns]
    x_label_df = clustering_result.cluster_df[columns].drop_duplicates()

    for i, column in enumerate(columns):
        if i == 0:
            new_labels = x_label_df[column]
        else:
            new_labels[new_labels == ""] = x_label_df.loc[new_labels == "", column]
    x_label_df = pd.DataFrame(
        {"x_label": new_labels, "cluster_ids": x_label_df["cluster_ids"]}
    ).set_index("cluster_ids")

    # Handle duplicate x_labels by appending numbers
    x_label_df["x_label"] = x_label_df.groupby("x_label")["x_label"].transform(
        lambda x: x if len(x) == 1 else [f"{v}({i + 1})" for i, v in enumerate(x)]
    )
    x_label_dict = x_label_df["x_label"].to_dict()

    heatmap_df.columns = heatmap_df.columns.map(x_label_dict)
    heatmap_df = heatmap_df[sorted(heatmap_df.columns)]
    cluster_count.index = cluster_count.index.map(x_label_dict)
    cluster_mean_cellsize.index = cluster_mean_cellsize.index.map(x_label_dict)

    col_ha = pch.HeatmapAnnotation(
        cell_count=pch.anno_barplot(
            cluster_count, legend=False, colors="grey", height=20
        ),
        cell_size=pch.anno_barplot(
            cluster_mean_cellsize, legend=False, colors="grey", height=20
        ),
        verbose=0,
    )

    cm = pch.ClusterMapPlotter(
        data=heatmap_df,
        top_annotation=col_ha,
        **preset_heatmap_kwargs,
    )
    return cm


def plot_clustering_heatmap(
    adata: ad.AnnData,
    clustering_result: ClusteringResult,
    features: list[str],
    figsize: tuple[int, int] = (10, 8),
    plot_value: str = "zscore",
    x_label: str = "cluster",
    preset_heatmap_kwargs: str = "PRESET_HEATMAP_KWARGS",
    **kwargs: dict[str, Any],
) -> plt.Figure:
    """
    Create a single heatmap figure showing feature patterns across clusters.

    Parameters
    ----------
    adata : ad.AnnData
        AnnData object containing the expression data.
    clustering_result : ClusteringResult
        Object containing clustering assignments and metadata.
    features : list[str]
        List of features to display.
    figsize : tuple[int, int], optional
        Figure dimensions (width, height) in inches, by default (10, 8).
    plot_value : str, optional
        Type of values to plot ("zscore" or "mean"), by default "zscore".
    x_label : str, optional
        Label for the x-axis, by default "cluster". Can be "cluster", "annotation",
        or "tag". If "cluster", the cluster IDs will be used as the x-axis labels.
        If "annotation" or "tag", the annotation or tag will be used as the x-axis
        labels if they are not empty. Otherwise, the cluster IDs will be used as
        the x-axis labels.
    preset_heatmap_kwargs : str, optional
        Name of preset kwargs for heatmap, by default "PRESET_HEATMAP_KWARGS".
    **kwargs : dict[str, Any]
        Additional kwargs passed to PyComplexHeatmap.ClusterMapPlotter.

    Returns
    -------
    plt.Figure
        The generated figure object.
    """
    clustering_id = clustering_result.clustering_id
    method = clustering_result.method

    cm = _plot_clustering_heatmap(
        adata,
        clustering_result,
        features,
        plot_value=plot_value,
        x_label=x_label,
        preset_heatmap_kwargs=preset_heatmap_kwargs,
        **kwargs,
    )

    fig, ax = plt.subplots(figsize=figsize)
    fig.suptitle(f"{clustering_id} ({method})")
    cm.plot(ax=ax)
    cm.plot_legends(ax=ax)

    return fig


def plot_clustering_heatmap_2(
    adata: ad.AnnData,
    clustering_result: ClusteringResult,
    features: list[str],
    figsize: tuple[int, int] = (20, 8),
    x_label: str = "cluster",
    col_gap: int = 30,
    legend_hpad: int = 50,
    preset_heatmap_kwargs: str = "PRESET_HEATMAP_KWARGS",
    kwargs_zscore: dict[str, Any] = {},
    kwargs_mean: dict[str, Any] = {},
) -> plt.Figure:
    """
    Create a dual heatmap figure showing both z-score and mean value patterns.

    Parameters
    ----------
    adata : ad.AnnData
        AnnData object containing the expression data.
    clustering_result : ClusteringResult
        Object containing clustering assignments and metadata.
    features : list[str]
        List of features to display.
    figsize : tuple[int, int], optional
        Figure dimensions (width, height) in inches, by default (20, 8).
    x_label : str, optional
        Label for the x-axis, by default "cluster". Can be "cluster", "annotation",
        or "tag". If "cluster", the cluster IDs will be used as the x-axis labels.
        If "annotation" or "tag", the annotation or tag will be used as the x-axis
        labels if they are not empty. Otherwise, the cluster IDs will be used as
        the x-axis labels.
    col_gap : int, optional
        Gap between the two heatmaps in pixels, by default 30.
    legend_hpad : int, optional
        Horizontal padding for legends in pixels, by default 50.
    preset_heatmap_kwargs : str, optional
        Name of preset kwargs for heatmap, by default "PRESET_HEATMAP_KWARGS".
    kwargs_zscore : dict[str, Any], optional
        Additional kwargs for z-score heatmap, by default {}.
    kwargs_mean : dict[str, Any], optional
        Additional kwargs for mean value heatmap, by default {}.

    Returns
    -------
    plt.Figure
        The generated figure object containing both heatmaps.
    """
    clustering_id = clustering_result.clustering_id
    method = clustering_result.method

    cm_1 = _plot_clustering_heatmap(
        adata,
        clustering_result,
        features,
        plot_value="zscore",
        x_label=x_label,
        preset_heatmap_kwargs=preset_heatmap_kwargs,
        **kwargs_zscore,
    )

    cm_2 = _plot_clustering_heatmap(
        adata,
        clustering_result,
        features,
        plot_value="mean",
        x_label=x_label,
        preset_heatmap_kwargs=preset_heatmap_kwargs,
        **kwargs_mean,
    )

    cmlist = [cm_1, cm_2]
    fig, ax = plt.subplots(figsize=figsize)
    ax, legend_axes = pch.composite(
        cmlist=cmlist,
        main=0,
        col_gap=col_gap,
        legend_hpad=legend_hpad,
        verbose=0,
    )
    ax.set_title(
        f"{clustering_id} ({method})",
        y=1.05,
    )
    plt.close(fig)

    return fig


# Plotting functions <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


# ClusteringResultManager >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


class ClusteringResultManager(BaseModel):
    """
    A class to manage the clustering results and generate metadata matrices.

    Attributes:
    -----------
    output_dir: Union[str, Path]
        The directory to store clustering results.
    unit_ids: list[str]
        All unit ids of the data to be clustered.
    summary_df: pd.DataFrame
        The summary DataFrame.
    non_explicit_df: pd.DataFrame
        The non-explicit DataFrame (with empty annotation) need to be subclustered.
    """

    output_dir: Union[str, Path]
    unit_ids: list[str]
    summary_df: pd.DataFrame = Field(default_factory=pd.DataFrame)
    non_explicit_df: pd.DataFrame = Field(default_factory=pd.DataFrame)

    model_config = {"arbitrary_types_allowed": True}

    # Custom initialization using model_validator in Pydantic v2
    @model_validator(mode="after")
    def init(self):
        """
        Initialize the clustering result manager.
        """
        self.output_dir = Path(self.output_dir)
        (self.output_dir / "clustering_results").mkdir(parents=True, exist_ok=True)

        clustering_sequence_file = self.output_dir / "clustering_sequence.txt"

        # Load clustering sequence if exists
        if clustering_sequence_file.exists():
            with open(clustering_sequence_file, "r") as f:
                clustering_sequence = [
                    line.strip() for line in f.readlines() if line.strip() != ""
                ]
            if len(clustering_sequence) == 0:
                print("No clustering sequence found.")
                return self
        else:
            print("No clustering sequence found.")
            return self

        clustering_ids = []
        annotations = []
        tags = []
        for clustering_id in tqdm(
            clustering_sequence,
            desc="Loading clustering results",
            bar_format=TQDM_FORMAT,
        ):
            clustering_file = (
                self.output_dir / "clustering_results" / f"{clustering_id}.csv"
            )
            if not clustering_file.exists():
                raise FileNotFoundError(f"Clustering result not found: {clustering_id}")
            clustering_df = pd.read_csv(clustering_file)

            # check if unit_ids is unique
            if clustering_df["unit_ids"].duplicated().any():
                raise ValueError(
                    "Clustering result has multiple unit ids: {clustering_id}"
                )

            # check if clustering_id is unique
            clustering_id = clustering_df["clustering_id"].unique()
            if len(clustering_id) > 1:
                raise ValueError(
                    f"Clustering result has multiple clustering ids: {clustering_id}"
                )
            else:
                clustering_id = clustering_id[0]

            # annotations
            annotations.append(
                clustering_df[["unit_ids", "annotation", "clustering_id"]]
            )

            # tags
            tags.append(
                clustering_df.drop(columns=["annotation", "cluster_ids", "method"])
            )

            # clustering_id
            clustering_df = clustering_df.drop(
                columns=["clustering_id", "method"]
            ).rename(columns={"cluster_ids": clustering_id})
            clustering_df[clustering_id] = clustering_df[clustering_id].astype(str)
            clustering_ids.append(clustering_df[["unit_ids", clustering_id]])

        # latest cluster id
        # clustering_ids = [
        #     clustering_id.set_index("unit_ids") for clustering_id in clustering_ids
        # ]
        # clustering_id_df = pd.concat(clustering_ids, axis=1).fillna("")
        # clustering_id_df["latest_cluster_id"] = clustering_id_df.apply(
        #     lambda x: "|".join([i for i in x if i != ""]), axis=1
        # )

        # annotation
        annotation_df = pd.concat(annotations, axis=0)
        annotation_df = annotation_df[
            (~annotation_df["annotation"].isna()) & (annotation_df["annotation"] != "")
        ].drop_duplicates()
        annotation_df_multi = (
            annotation_df.drop_duplicates(["unit_ids", "annotation"])
            .groupby(["unit_ids", "annotation"])
            .size()
            .reset_index(name="count")
            .query("count > 1")
        )
        if len(annotation_df_multi) > 0:
            raise ValueError(
                "Clustering result has multiple annotations for the same unit."
            )

        annotation_df_multi_clustering_id = (
            annotation_df.groupby(["unit_ids", "annotation"])
            .size()
            .reset_index(name="count")
            .query("count > 1")
        )
        duplicated_clustering_ids = annotation_df[
            annotation_df["unit_ids"].isin(
                annotation_df_multi_clustering_id["unit_ids"]
            )
        ]["clustering_id"].unique()
        if len(annotation_df_multi_clustering_id) > 0:
            raise ValueError(
                f"Duplicated clustering result with same annotations: {duplicated_clustering_ids}."
            )
        annotation_df = annotation_df.set_index("unit_ids")

        # tags
        tags_df = pd.concat(tags, axis=0)
        tags_columns = tags_df.drop(columns=["unit_ids", "clustering_id"]).columns

        tag_dfs = []
        for tag_column in tqdm(
            tags_columns, desc="Processing tags", bar_format=TQDM_FORMAT
        ):
            tag_df = tags_df[["unit_ids", tag_column]]
            tag_df = tag_df[(~tag_df[tag_column].isna()) & (tag_df[tag_column] != "")]
            tag_df = (
                tag_df.groupby(["unit_ids"])[tag_column]
                .apply(lambda x: "|".join([i for i in x if i != ""]))
                .to_frame(name=tag_column)
            )
            tag_dfs.append(tag_df)
        tags_df = pd.concat(tag_dfs, axis=1)

        # summary_df = pd.concat([clustering_id_df, annotation_df, tags_df], axis=1)
        summary_df = pd.concat([annotation_df, tags_df], axis=1)
        self.summary_df = (
            pd.DataFrame(index=self.unit_ids)
            .merge(summary_df, left_index=True, right_index=True, how="left")
            .fillna("")
        )
        self.non_explicit_df = self.summary_df.query("annotation == ''")
        return self


# ClusteringResultManager <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


# Custom functions >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


def update_geojson_from_clustering_result(
    geojson_file: Union[str, Path],
    clustering_result: ClusteringResult,
    output_dir: Union[str, Path],
):
    try:
        from pyqupath.geojson import GeojsonProcessor
    except ImportError:
        raise ImportError(
            "pyqupath is not installed. Please install it using `pip install git+https://github.com/wuwenrui555/pyqupath.git@v0.0.5`."
        )

    geojson_file = Path(geojson_file)
    geojson = GeojsonProcessor.from_path(geojson_file)

    cluster_df = clustering_result.cluster_df[["unit_ids", "cluster_ids"]].copy()
    cluster_df["id"] = cluster_df["unit_ids"].str.split(r"_(?=c\d)").str[0]
    cluster_df["cell_label"] = cluster_df["unit_ids"].str.split(r"_c(?=\d)").str[1]
    name_dict = (
        cluster_df[cluster_df["id"] == geojson_file.stem]
        .set_index("cell_label")["cluster_ids"]
        .to_dict()
    )
    # select the cells involved in the clustering
    geojson.gdf = geojson.gdf[geojson.gdf["name"].isin(name_dict.keys())]
    geojson.update_classification(name_dict)

    output_dir = Path(output_dir)
    output_file = (
        output_dir / "geojson" / clustering_result.clustering_id / geojson_file.name
    )
    output_file.parent.mkdir(parents=True, exist_ok=True)
    geojson.output_geojson(output_file)


# Custom functions <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

# %%
if __name__ == "__main__":
    # %%
    markers_all = [
        "CD45",
        "CD3e",
        "CD8",
        "CD4",
        "FoxP3",
        "CD20",
        "CD68",
        "CD163",
        "CD16",
        "CD11b",
        "MPO",
        "Cytokeratin",
        "CD31",
        "Podoplanin",
        "aSMA",
    ]
    adata = ad.read_h5ad("input/data_demo.h5ad")[0:1000].copy()
    # unit_ids = adata.obs.index[0:1000].tolist()
    features = markers_all

    manager = ClusteringResultManager(
        output_dir="output/clustering_demo", unit_ids=adata.obs.index
    )
    manager.summary_df

    # %%
    clustering_result = ClusteringResult(
        clustering_id="1",
        method="1",
        unit_ids=manager.summary_df.index,
        cluster_ids=manager.summary_df["annotation"],
    )
    # %%
    # %%
    fig = plot_clustering_heatmap(
        adata,
        clustering_result,
        features,
        plot_value="mean",
        figsize=(10, 8),
    )
    # %%
    fig = plot_clustering_heatmap(
        adata,
        clustering_result,
        features,
        plot_value="mean",
        figsize=(10, 8),
        z_score=0,
        cmap="RdBu_r",
    )
    # %%
    fig = plot_clustering_heatmap(
        adata,
        clustering_result,
        features,
        plot_value="zscore",
        figsize=(10, 8),
    )
# %%
